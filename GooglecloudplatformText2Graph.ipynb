{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTACIÓN DE PHI-3 EN GOOGLE CLOUD PLATFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origen\n",
    "REGION = \"us-central1\"\n",
    "PROJECT_ID = \"vernal-guide-414621\"\n",
    "BIGQUERY = \"jgj767\"\n",
    "TABLE = \"igilñ\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destino \n",
    "REGION = \"us-central1\"\n",
    "PROJECT_ID = \"vernal-guide-414621\"\n",
    "DATASET_ID = \"news\"  \n",
    "TABLE_ID= \"Graph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir la función que extraera las noticias filtradas, dejando en una tabla de BigQuery nueva solamente las noticias que involucren personas políticas y sean de temas políticos\n",
    "### Función .py que ira a google functions y se automatizara semanalmente con google scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notas: Buscar las noticias con la mayor cantidad de personas, para hacer que la inferencia recoga la mayor cantidad de información, asi aprovechar los recursos y poder realizarlo economicamente. Ojala llegar a alrededor de un maximo 600-750-1000 noticias semanales para en un dia realizar una tanda de inferencia.\n",
    "Maximizar personas y minimizar palabras. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proximo paso, generar una columna con el numero de palabras y el numero de personas, definir cuantas noticias uno quiere semanalmente ( apropiado = 750), generar la funcion de google cloud function, implementarla en google scheduler, implementar el modelo semanalmente (1 tanda de inferencia), arreglar manualmente la tabla. Ultimo paso, teniendo una basta cantidad de informacion, entrenar el modelo definitivo, implementarlo en un endpoint. analizar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import re\n",
    "from google.cloud.exceptions import NotFound\n",
    "import json\n",
    "import datetime\n",
    "personas_red_politica_dict = {'Maria Acevedo': 'diputado', 'Eric Aedo': 'diputado', 'Yovana Ahumada': 'diputado', 'Jorge Alessandri': 'diputado', 'Rene Alinco': 'diputado', 'Jaime Araya': 'diputado', 'Cristian Araya': 'diputado', 'Monica Arce': 'diputado', 'Roberto Arroyo': 'diputado', 'Danisa Astudillo': 'diputado', 'Chiara Barchiesi': 'diputado', 'Boris Barrera': 'diputado', 'Hector Barria': 'diputado', 'Miguel Becker': 'diputado', 'Maria Francisca Bello': 'diputado', 'Juan Carlos Beltran': 'diputado', 'Gustavo Benavente': 'diputado', 'Bernardo Berger': 'diputado', 'Alejandro Bernales': 'diputado', 'Carlos Bianchi': 'senador', 'Sergio Bobadilla': 'diputado', 'Fernando Borquez': 'diputado', 'Ana Maria Bravo': 'diputado', 'Marta Bravo': 'diputado', 'Jorge Brito': 'diputado', 'Felix Bugueno': 'diputado', 'Mercedes Bulnes': 'diputado', 'Miguel Angel Calisto': 'diputado', 'Felipe Camano': 'diputado', 'Karol Cariola': 'diputado', 'Alvaro Carter': 'diputado', 'Nathalie Castillo': 'diputado', 'Jose Miguel Castro': 'diputado', 'Andres Celis': 'diputado', 'Daniella Cicardini': 'diputado', 'Sofia Cid': 'diputado', 'Ricardo Cifuentes': 'diputado', 'Juan Antonio Coloma': 'diputado', 'Sara Concha': 'diputado', 'Maria Luisa Cordero': 'diputado', 'Eduardo Cornejo': 'diputado', 'Luis Cuello': 'diputado', 'Gonzalo De la Carrera': 'diputado', 'Tomas Derementeria': 'diputado', 'Catalina del Real': 'diputado', 'Viviana Delgado': 'diputado', 'Felipe Donoso': 'diputado', 'Jorge Duran': 'diputado', 'Eduardo Duran': 'diputado', 'Camila Flores': 'diputado', 'Lorena Fries': 'diputado', 'Juan Fuenzalida': 'diputado', 'Ana Maria Gazmuri': 'diputado', 'Andres Giordano': 'diputado', 'Felix Gonzalez': 'diputado', 'Marta Gonzalez': 'diputado', 'Mauro Gonzalez': 'diputado', 'Jorge Guzman': 'diputado', 'Carmen Hertz': 'diputado', 'Tomas Hirsch': 'diputado', 'Diego Ibanez': 'diputado', 'Marcos Ilabaca': 'diputado', 'Juan Irarrazaval': 'diputado', 'Pamela Jiles': 'diputado', 'Andres Jouannet': 'diputado', 'Harry Jurgensen': 'diputado', 'Johannes Kaiser': 'diputado', 'Cristian Labbe': 'diputado', 'Paula Labra': 'diputado', 'Tomas Lagomarsino': 'diputado', 'Joaquin Lavin': 'diputado', 'Henry Leal': 'diputado', 'Enrique Lee': 'diputado', 'Raul Leiva': 'diputado', 'Daniel Lilayu': 'diputado', 'Andres Longton': 'diputado', 'Luis Malla': 'diputado', 'Daniel Manouchehri': 'diputado', 'Cristobal Martinez': 'diputado', 'Carolina Marzan': 'diputado', 'Christian Matheson': 'diputado', 'Karen Medina': 'diputado', 'Cosme Mellado': 'diputado', 'Miguel Mellado': 'diputado', 'Daniel Melo': 'diputado', 'Jose Meza': 'diputado', 'Vlado Mirosevic': 'diputado', 'Claudia Mix': 'diputado', 'Helia Molina': 'diputado', 'Javiera Morales': 'diputado', 'Carla Morales': 'diputado', 'Cristhian Moreira': 'diputado', 'Benjamin Moreno': 'diputado', 'Jaime Mulet': 'diputado', 'Francesca Munoz': 'diputado', 'Camila Musante': 'diputado', 'Jaime Naranjo': 'diputado', 'Gloria Naveillan': 'diputado', 'Emilia Nuyado': 'diputado', 'Ericka Nanco': 'diputado', 'Mauricio Ojeda': 'diputado', 'Erika Olivera': 'diputado', 'Maite Orsini': 'diputado', 'Ximena Ossandon': 'diputado', 'Ruben Oyarzo': 'diputado', 'Hernan Palma': 'diputado', 'Marlene Perez': 'diputado', 'Joanna Perez': 'diputado', 'Catalina Perez': 'diputado', 'Victor Pino': 'diputado', 'Lorena Pizarro': 'diputado', 'Alejandra Placencia': 'diputado', 'Francisco Pulgar': 'diputado', 'Guillermo Ramirez': 'diputado', 'Matias Ramirez': 'diputado', 'Marcia Raphael': 'diputado', 'Jorge Rathgeb': 'diputado', 'Hugo Rey': 'diputado', 'Marcela Riquelme': 'diputado', 'Grivas': 'diputado', 'Camila Rojas': 'diputado', 'Agustin Romero': 'diputado', 'Leonidas Romero': 'diputado', 'Natalia Romero': 'diputado', 'Patricio Rosas': 'diputado', 'Jaime Saez': 'diputado', 'Jorge Saffirio': 'diputado', 'Clara Sagardia': 'diputado', 'Luis Sanchez': 'diputado', 'Juan Santana': 'diputado', 'Marisela Santibanez': 'diputado', 'Frank Sauerbaum': 'diputado', 'Diego Schalper': 'diputado', 'Emilia Schneider': 'diputado', 'Stephan Schubert': 'diputado', 'Alexis Sepulveda': 'diputado', 'Daniela Serrano': 'diputado', 'Leonardo Soto': 'diputado', 'Raul Soto': 'diputado', 'Marco Sulantay': 'diputado', 'Cristian Tapia': 'diputado', 'Hotuiti Teao': 'diputado', 'Carolina Tello': 'diputado', 'Renzo Trisot\\xa0\\xa0t\\xa0\\xa0i\\xa0\\xa0': 'diputado', 'Hector Ulloa': 'diputado', 'Francisco Undurraga': 'diputado', 'Alberto Undurraga': 'diputado', 'Cristobal Urruticoechea': 'diputado', 'Consuelo Veloso': 'diputado', 'Nelson Venegas': 'diputado', 'Sebastian Videla': 'diputado', 'Gaston Von Muhlenbrock': 'diputado', 'Flor Weisse': 'diputado', 'Gonzalo Winter': 'diputado', 'Gael Yeomans': 'diputado', 'José Miguel Insulza': 'senador', 'José Durana Semir': 'senador', 'Jorge Soria ': 'senador', 'Luz Ebensperger ': 'senador', 'Pedro Araya ': 'senador', 'Esteban Velásquez ': 'senador', 'Paulina Núñez ': 'senador', 'Yasna Provoste': 'senador', 'Rafael Prohens': 'senador', 'Daniel Núñez\\xa0': 'senador', 'Matias Walker': 'senador', 'Sergio Gahona': 'senador', 'Fracisco Chahuan': 'senador', 'Kenneth Pugh': 'senador', 'Ricardo Lagos Weber': 'senador', 'Isabel Allende': 'senador', 'Juan Ignacio Latorre': 'senador', 'Manuel Jose Ossandon': 'senador', 'Luciano Cruz Coke ': 'senador', 'Claudia Pascual': 'senador', 'Fabiola Campillai': 'senador', 'Rojo Edwards': 'senador', 'Alejandro Sepulveda': 'senador', 'Javier Macaya': 'senador', 'Juan Luis Castro Gonzalez': 'senador', 'Juan Castro Prieto': 'senador', 'Rodrigo Galilea': 'senador', 'Juan Antonio Coloma Correa': 'senador', 'Ximena Rincon': 'senador', 'Paulina Vodanovic': 'senador', 'Sebastian Keitel Bianchi': 'senador', 'Enrique van Rysselberghe': 'senador', 'Gaston Saavedra': 'senador', 'Loreto Carvajal': 'senador', 'Gustavo Sanhueza': 'senador', 'Felipe Kast': 'senador', 'Francisco Huenchumilla': 'senador', 'Jaime Quintana': 'senador', 'Jose Garcia': 'senador', 'Carmen Gloria Aravena': 'senador', 'Alfonso Longton': 'senador', 'Maria Jose Gatica': 'senador', 'Ivan Flores': 'senador', 'Ivan Moreira ': 'senador', 'Fidel Espinoza': 'senador', 'Carlos Kuschel': 'senador', 'David Sandoval': 'senador', 'Ximena Ordenes': 'senador', 'Karim Bianchi': 'senador', 'Alejandro Kusanovic': 'senador', 'Carolina Toha': 'ministro', 'Maya Fernandez': 'ministro', 'Alberto van Klaveren': 'ministro', 'Mario Marcel': 'ministro', 'Alvaro Elizalde': 'ministro', 'Camila Vallejo': 'ministro', 'Nicolas Grau': 'ministro', 'Javiera Toro': 'ministro', 'Nicolas Cataldo': 'ministro', 'Luis Cordero': 'ministro', 'Jeannette Jara': 'ministro', 'Jessica Lopez': 'ministro', 'Ximena Aguilera': 'ministro', 'Carlos Montes': 'ministro', 'Esteban Valenzuela': 'ministro', 'Aurora Williams': 'ministro', 'Juan Carlos Muñoz': 'ministro', 'Marcela Sandoval': 'ministro', 'Diego Pardow': 'ministro', 'Maisa Rojas': 'ministro', 'Jaime Pizarro': 'ministro', 'Antonia Orellana': 'ministro', 'Carolina Arredondo': 'ministro', 'Aisen Etcheverry': 'ministro', 'Gabriel Boric': 'presidente', 'Sebastian Piñera': 'expresidente', 'Michelle Bachelet': 'expresidente', 'Ricardo Lagos Escobar': 'expresidente', 'Eduardo Frei Ruiz-Tagle': 'expresidente', 'Patricio Aylwin': 'expresidente'}\n",
    "keywords = [\"diputado\", \"diputada\", \"senador\", \"senadora\", \"Cámara\", \"parlamentarios\", \"bancada\"]\n",
    "\n",
    "# Inicializa el cliente de BigQuery\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Función para descargar datos de BigQuery y preprocesarlos\n",
    "def preprocess_data():\n",
    "    # Define tu consulta SQL para extraer datos de la tabla\n",
    "    query = \"\"\"\n",
    "        SELECT title, body, title_1, date FROM `vernal-guide-414621.jgj767.igilñ`\n",
    "    \"\"\"\n",
    "\n",
    "    # Ejecuta la consulta\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    # Obtén los resultados de la consulta y conviértelos a un DataFrame de pandas\n",
    "    df = query_job.to_dataframe()\n",
    "    \n",
    "    # Procesa los datos\n",
    "    processed_data = preprocesar_text_solo_noticias(df)\n",
    "    \n",
    "    # Inserta los datos procesados en BigQuery\n",
    "    insert_to_bigquery(processed_data)\n",
    "\n",
    "# Función para preprocesar el texto de las noticias\n",
    "def preprocesar_text_solo_noticias(df):\n",
    "    # Se añaden entidades detectadas como 'Personas' en una nueva columna, evitando SettingWithCopyWarning\n",
    "    df.drop_duplicates(subset=['body'], inplace=True)\n",
    "    df['body_length'] = df['body'].str.len()\n",
    "    df = df[df['body_length'] > 500]\n",
    "    df = df[df['body_length'] < 2000]\n",
    "\n",
    "    def filtrar_noticias(noticia):\n",
    "        # Búsqueda de palabras clave\n",
    "        contiene_palabra_clave = any(keyword in noticia.lower() for keyword in keywords)\n",
    "\n",
    "        # Búsqueda de nombres de personas de la red política\n",
    "        contiene_nombre_persona = any(re.search(nombre, noticia, re.IGNORECASE) for nombre in personas_red_politica_dict.keys())\n",
    "\n",
    "        # La noticia se conservará si cumple con al menos uno de los criterios\n",
    "        return contiene_palabra_clave or contiene_nombre_persona\n",
    "\n",
    "    df['filtrar'] = df['body'].apply(filtrar_noticias)\n",
    "    df = df[df['filtrar']]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Función para insertar los datos procesados en BigQuery\n",
    "def insert_to_bigquery(data):\n",
    "    # Define el ID del proyecto y el ID del dataset donde se encuentra la tabla de destino\n",
    "    project_id = 'vernal-guide-414621'\n",
    "    dataset_id = 'news'\n",
    "    table_id = 'inference'\n",
    "\n",
    "    # Construye una referencia a la tabla de destino\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    \n",
    "    # Intenta obtener la tabla, si no existe, la creará\n",
    "    try:\n",
    "        table = client.get_table(table_ref)\n",
    "    except NotFound:\n",
    "        schema = [\n",
    "            bigquery.SchemaField(\"body\", \"STRING\"),\n",
    "            # Agrega aquí más campos si es necesario\n",
    "        ]\n",
    "        table = bigquery.Table(table_ref, schema=schema)\n",
    "        table = client.create_table(table)\n",
    "\n",
    "    # Convertir el DataFrame a una lista de diccionarios\n",
    "    # Convertir el DataFrame a una lista de diccionarios\n",
    "    rows_to_insert = data.to_dict(orient='records')\n",
    "\n",
    "    # Convertir valores de fecha a cadena de texto\n",
    "    for row in rows_to_insert:\n",
    "        if 'date' in row and isinstance(row['date'], datetime.date):\n",
    "            row['date'] = row['date'].strftime('%Y-%m-%d')\n",
    "    # Inserta los datos en la tabla de destino utilizando el esquema existente\n",
    "    errors = client.insert_rows_json(table_ref, rows_to_insert)\n",
    "\n",
    "    # Maneja cualquier error que ocurra durante la inserción\n",
    "    if errors:\n",
    "        for error in errors:\n",
    "            print(f'Error al insertar fila: {error}')\n",
    "    else:\n",
    "        print('Datos insertados correctamente en BigQuery.')\n",
    "        \n",
    "# Esta es la entrada de la Cloud Function\n",
    "def main(request):\n",
    "    preprocess_data()\n",
    "    return \"Proceso de preprocesamiento y carga completado.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba función pulp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de nueva metodologia (se necesitara agregar 2 columnas, y un conteo de noticias & numero de noticias requeridas a la semana por ahora 750): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado de la solución: Optimal\n",
      "Noticia 1: No seleccionada\n",
      "Noticia 2: Seleccionada\n",
      "Noticia 3: No seleccionada\n",
      "Noticia 4: Seleccionada\n",
      "Noticia 5: Seleccionada\n",
      "Valor de la función objetivo: -103.0\n"
     ]
    }
   ],
   "source": [
    "import pulp\n",
    "\n",
    "# Datos de ejemplo (reemplazar con tus datos reales)\n",
    "N = 5  # Número de noticias\n",
    "P = [3, 2, 5, 1, 4]  # Número de personas políticas relevantes mencionadas en cada noticia\n",
    "L = [1500, 800, 1200, 500, 900]  # Longitud del cuerpo de cada noticia\n",
    "lambda_ = 0.05  # Parámetro lambda para balancear la función objetivo\n",
    "k = 3  # Número específico de noticias a seleccionar\n",
    "\n",
    "# Crear el problema de maximización\n",
    "prob = pulp.LpProblem(\"Maximizar_Presencias_Politicas\", pulp.LpMaximize)\n",
    "\n",
    "# Variables de decisión: x_i indica si la noticia i es seleccionada (1) o no (0)\n",
    "x = [pulp.LpVariable(f\"x{i}\", cat='Binary') for i in range(N)]\n",
    "\n",
    "# Función objetivo\n",
    "prob += pulp.lpSum(P[i] * x[i] for i in range(N)) - lambda_ * pulp.lpSum(L[i] * x[i] for i in range(N))\n",
    "\n",
    "# Restricción: Seleccionar exactamente k noticias\n",
    "prob += pulp.lpSum(x) == k, \"Seleccionar_k_noticias\"\n",
    "\n",
    "# Resolver el problema\n",
    "prob.solve()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Estado de la solución:\", pulp.LpStatus[prob.status])\n",
    "for i in range(N):\n",
    "    print(f\"Noticia {i+1}: {'Seleccionada' if x[i].varValue == 1 else 'No seleccionada'}\")\n",
    "\n",
    "# Valor de la función objetivo\n",
    "print(\"Valor de la función objetivo:\", pulp.value(prob.objective))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar inferencia con el modelo de HuggingFace y arreglarlas manualmente, posteriormente guardarlas nuevamente en la tabla de BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
